{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit√© Bonus 2 : Observabilit√© et √©valuation des agents\n",
    "\n",
    "Dans ce tutoriel, nous allons apprendre √† **surveiller les √©tapes internes (traces) de notre agent** et **√©valuer sa performance** en utilisant des outils d'observabilit√© open-source.\n",
    "\n",
    "La capacit√© d'observer et d'√©valuer le comportement d'un agent est essentielle pour :\n",
    "- D√©boguer les probl√®mes lorsque les t√¢ches √©chouent ou produisent des r√©sultats sous-optimaux\n",
    "- Contr√¥ler les co√ªts et les performances en temps r√©el\n",
    "- Am√©liorer la fiabilit√© et la s√©curit√© gr√¢ce √† un retour d'information continu\n",
    "\n",
    "Ce *notebook* fait partie du [Cours sur les agents d'Hugging Face](https://huggingface.co/learn/agents-course/fr)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pr√©requis de l'exercice üèóÔ∏è\n",
    "\n",
    "Avant d'ex√©cuter ce *notebook*, assurez-vous d'avoir :\n",
    "\n",
    "üî≤ üìö **Etudier la section [Introduction aux agents](https://huggingface.co/learn/agents-course/fr/unit1/introduction)**\n",
    "\n",
    "üî≤ üìö **Etudier la section [le *framework* smolagents](https://huggingface.co/learn/agents-course/fr/unit2/smolagents/introduction)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## √âtape 0 : Installer les biblioth√®ques n√©cessaires\n",
    "\n",
    "Nous aurons besoin de quelques biblioth√®ques qui nous permettront d'ex√©cuter, de contr√¥ler et d'√©valuer nos agents :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langfuse 'smolagents[telemetry]' openinference-instrumentation-smolagents datasets 'smolagents[gradio]' gradio --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## √âtape 1 : Instrumenter votre agent\n",
    "\n",
    "Dans ce *notebook*, nous utiliserons [Langfuse](https://langfuse.com/) comme outil d'observabilit√©, mais vous pouvez utiliser **n'importe quel autre service compatible avec OpenTelemetry**. Le code ci-dessous montre comment d√©finir les variables d'environnement pour Langfuse (ou n'importe quel *endpoint OTel*) et comment instrumenter votre smolagent.\n",
    "\n",
    "**Note :** Si vous utilisez LlamaIndex ou LangGraph, vous pouvez trouver de la documentation sur leur instrumentation [ici](https://langfuse.com/docs/integrations/llama-index/workflows) et [ici](https://langfuse.com/docs/integrations/langchain/example-python-langgraph)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Obtenez les cl√©s de votre projet √† partir de la page des param√®tres du projet : https://cloud.langfuse.com\n",
    "os.environ[\"LANGFUSE_PUBLIC_KEY\"] = \"pk-lf-...\" \n",
    "os.environ[\"LANGFUSE_SECRET_KEY\"] = \"sk-lf-...\" \n",
    "os.environ[\"LANGFUSE_HOST\"] = \"https://cloud.langfuse.com\" # üá™üá∫  r√©gion EU\n",
    "# os.environ[\"LANGFUSE_HOST\"] = \"https://us.cloud.langfuse.com\" # üá∫üá∏ r√©gion US\n",
    "\n",
    "# D√©finissez vos tokens/secrets Hugging Face comme variable d'environnement\n",
    "os.environ[\"HF_TOKEN\"] = \"hf_...\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les variables d'environnement √©tant d√©finies, nous pouvons maintenant initialiser le client de Langfuse `get_client()` initialise le client Langfuse en utilisant les informations d'identification fournies dans les variables d'environnement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langfuse client is authenticated and ready!\n"
     ]
    }
   ],
   "source": [
    "from langfuse import get_client\n",
    " \n",
    "langfuse = get_client()\n",
    " \n",
    "# Verify connection\n",
    "if langfuse.auth_check():\n",
    "    print(\"Langfuse client is authenticated and ready!\")\n",
    "else:\n",
    "    print(\"Authentication failed. Please check your credentials and host.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attempting to instrument while already instrumented\n"
     ]
    }
   ],
   "source": [
    "from openinference.instrumentation.smolagents import SmolagentsInstrumentor\n",
    " \n",
    "SmolagentsInstrumentor().instrument()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## √âtape 2 : Testez votre instrumentation\n",
    "\n",
    "Voici un simple CodeAgent de smolagents qui calcule `1+1`. Nous l'ex√©cutons pour confirmer que l'instrumentation fonctionne correctement. Si tout est configur√© correctement, vous verrez des logs/spans dans votre tableau de bord d'observabilit√©."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import InferenceClientModel, CodeAgent\n",
    "\n",
    "# Cr√©er un agent basique pour tester l'instrumentation\n",
    "agent = CodeAgent(\n",
    "    tools=[],\n",
    "    model=InferenceClientModel()\n",
    ")\n",
    "\n",
    "agent.run(\"1+1=\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consultez votre [Langfuse Traces Dashboard](https://cloud.langfuse.com/traces) (ou l'outil d'observabilit√© de votre choix) pour confirmer que les port√©es et les logs ont √©t√© enregistr√©s.\n",
    "\n",
    "Exemple de capture d'√©cran de Langfuse :\n",
    "\n",
    "![Example trace in Langfuse](https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/bonus-unit2/first-example-trace.png)\n",
    "\n",
    "_[Lien vers la trace](https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/1b94d6888258e0998329cdb72a371155?timestamp=2025-03-10T11%3A59%3A41.743Z)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## √âtape 3 : Observer et √©valuer un agent plus complexe\n",
    "\n",
    "Maintenant que vous avez confirm√© que votre instrumentation fonctionne, essayons une requ√™te plus complexe afin de voir comment les mesures avanc√©es (utilisation des *tokens*, latence, co√ªts, etc.) sont suivies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import (CodeAgent, DuckDuckGoSearchTool, InferenceClientModel)\n",
    "\n",
    "search_tool = DuckDuckGoSearchTool()\n",
    "agent = CodeAgent(tools=[search_tool], model=InferenceClientModel())\n",
    "\n",
    "agent.run(\"How many Rubik's Cubes could you fit inside the Notre Dame Cathedral?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure de la trace\n",
    "\n",
    "La plupart des outils d'observabilit√© enregistrent une **trace** qui contient des **spans**, qui repr√©sentent chaque √©tape de la logique de votre agent. Ici, la trace contient l'ex√©cution globale de l'agent et les sous-p√©riodes pour :\n",
    "- les appels √† l'outil (DuckDuckGoSearchTool)\n",
    "- Les appels LLM (InferenceClientModel)\n",
    "\n",
    "Vous pouvez les inspecter pour voir pr√©cis√©ment o√π le temps est pass√©, combien de *tokens* sont utilis√©s, etc. :\n",
    "\n",
    "![Trace tree in Langfuse](https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/bonus-unit2/trace-tree.png)\n",
    "\n",
    "_[Lien vers la trace](https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/1ac33b89ffd5e75d4265b62900c348ed?timestamp=2025-03-07T13%3A45%3A09.149Z&display=preview)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## √âvaluation en ligne\n",
    "\n",
    "Dans la section pr√©c√©dente, nous avons appris la diff√©rence entre l'√©valuation en ligne et hors ligne. Nous allons maintenant voir comment surveiller votre agent en production et l'√©valuer en direct.\n",
    "\n",
    "### M√©triques courantes √† suivre en production\n",
    "\n",
    "1. **Co√ªts** - L'instrumentation smolagents capture l'utilisation des *tokens*, que vous pouvez transformer en co√ªts approximatifs en assignant un prix par *token*.\n",
    "2. **Latence** - Observez le temps n√©cessaire √† la r√©alisation de chaque √©tape ou de l'ensemble de l'ex√©cution.\n",
    "3. **Retour utilisateur** - Les utilisateurs peuvent fournir un retour direct (pouce vers le haut/vers le bas) pour aider √† affiner ou √† corriger l'agent.\n",
    "4. ***LLM-as-a-Judge*** - Utilisez un autre LLM pour √©valuer les r√©sultats de votre agent en quasi temps r√©el (par exemple, v√©rification de la toxicit√© ou de l'exactitude des r√©sultats).\n",
    "\n",
    "Ci-dessous, nous montrons des exemples de ces m√©triques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Co√ªts\n",
    "\n",
    "Vous trouverez ci-dessous une capture d'√©cran montrant l'utilisation des appels `Qwen2.5-Coder-32B-Instruct`. Ceci est utile pour voir les √©tapes co√ªteuses et optimiser votre agent.\n",
    "\n",
    "![Costs](https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/bonus-unit2/smolagents-costs.png)\n",
    "\n",
    "_[Lien vers la trace](https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/1ac33b89ffd5e75d4265b62900c348ed?timestamp=2025-03-07T13%3A45%3A09.149Z&display=preview)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Temps de latence\n",
    "\n",
    "Nous pouvons √©galement voir combien de temps a dur√© chaque √©tape. Dans l'exemple ci-dessous, l'ensemble de la conversation a dur√© 32 secondes, que vous pouvez r√©partir par √©tape. Cela vous permet d'identifier les goulets d'√©tranglement et d'optimiser votre agent.\n",
    "\n",
    "![Latency](https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/bonus-unit2/smolagents-latency.png)\n",
    "\n",
    "_[Lien vers la trace](https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/1ac33b89ffd5e75d4265b62900c348ed?timestamp=2025-03-07T13%3A45%3A09.149Z&display=preview)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Attributs suppl√©mentaires\n",
    "\n",
    "Vous pouvez √©galement passer des attributs suppl√©mentaires √† vos spans. Ceux-ci peuvent inclure `user_id`, `tags`, `session_id`, et des m√©tadonn√©es personnalis√©es. Enrichir les traces avec ces d√©tails est important pour l'analyse, le d√©bogage et la surveillance du comportement de votre application √† travers diff√©rents utilisateurs ou sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import (CodeAgent, DuckDuckGoSearchTool, InferenceClientModel)\n",
    "\n",
    "search_tool = DuckDuckGoSearchTool()\n",
    "agent = CodeAgent(\n",
    "    tools=[search_tool],\n",
    "    model=InferenceClientModel()\n",
    ")\n",
    "\n",
    "with langfuse.start_as_current_span(\n",
    "    name=\"Smolagent-Trace\",\n",
    "    ) as span:\n",
    "    \n",
    "    # Lancez votre application ici\n",
    "    response = agent.run(\"What is the capital of Germany?\")\n",
    " \n",
    "    # Transmettre des attributs suppl√©mentaires au span\n",
    "    span.update_trace(\n",
    "        input=\"What is the capital of Germany?\",\n",
    "        output=response,\n",
    "        user_id=\"smolagent-user-123\",\n",
    "        session_id=\"smolagent-session-123456789\",\n",
    "        tags=[\"city-question\", \"testing-agents\"],\n",
    "        metadata={\"email\": \"user@langfuse.com\"},\n",
    "        )\n",
    " \n",
    "langfuse.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Enhancing agent runs with additional metrics](https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/bonus-unit2/smolagents-attributes.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Retour utilisateur\n",
    "\n",
    "Si votre agent est int√©gr√© dans une interface utilisateur, vous pouvez enregistrer les r√©actions directes de l'utilisateur (comme un pouce lev√© ou baiss√© dans une interface de discussion). Vous trouverez ci-dessous un exemple utilisant [Gradio](https://gradio.app/) pour int√©grer un chat avec un m√©canisme de retour d'information simple.\n",
    "\n",
    "Dans l'extrait de code ci-dessous, lorsqu'un utilisateur envoie un message de chat, nous capturons la trace dans Langfuse. Si l'utilisateur aime ou n'aime pas la derni√®re r√©ponse, nous attribuons un score √† la trace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from smolagents import (CodeAgent, InferenceClientModel)\n",
    "from langfuse import get_client\n",
    "\n",
    "langfuse = get_client()\n",
    "\n",
    "model = InferenceClientModel()\n",
    "agent = CodeAgent(tools=[], model=model, add_base_tools=True)\n",
    "\n",
    "trace_id = None\n",
    "\n",
    "def respond(prompt, history):\n",
    "    with langfuse.start_as_current_span(\n",
    "        name=\"Smolagent-Trace\"):\n",
    "        \n",
    "        # Ex√©cuter l'application\n",
    "        output = agent.run(prompt)\n",
    "\n",
    "        global trace_id\n",
    "        trace_id = langfuse.get_current_trace_id()\n",
    "\n",
    "    history.append({\"role\": \"assistant\", \"content\": str(output)})\n",
    "    return history\n",
    "\n",
    "def handle_like(data: gr.LikeData):\n",
    "    # √Ä titre de d√©monstration, nous mappons les retours utilisateurs une valeur de 1 (j'aime) ou de 0 (je n'aime pas)\n",
    "    if data.liked:\n",
    "        langfuse.create_score(\n",
    "            value=1,\n",
    "            name=\"user-feedback\",\n",
    "            trace_id=trace_id\n",
    "        )\n",
    "    else:\n",
    "        langfuse.create_score(\n",
    "            value=0,\n",
    "            name=\"user-feedback\",\n",
    "            trace_id=trace_id\n",
    "        )\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot(label=\"Chat\", type=\"messages\")\n",
    "    prompt_box = gr.Textbox(placeholder=\"Type your message...\", label=\"Your message\")\n",
    "\n",
    "    # Lorsque l'utilisateur appuie sur \"Enter\", nous ex√©cutons 'respond'\n",
    "    prompt_box.submit(\n",
    "        fn=respond,\n",
    "        inputs=[prompt_box, chatbot],\n",
    "        outputs=chatbot\n",
    "    )\n",
    "\n",
    "    # Lorsque l'utilisateur clique sur le bouton \"J'aime\" d'un message, nous ex√©cutons 'handle_like'\n",
    "    chatbot.like(handle_like, None, None)\n",
    "\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les retours des utilisateurs sont ensuite saisis dans votre outil d'observabilit√© :\n",
    "\n",
    "![User feedback is being captured in Langfuse](https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/bonus-unit2/user-feedback-gradio.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. LLM-as-a-Judge\n",
    "\n",
    "LLM-as-a-Judge est une autre fa√ßon d'√©valuer automatiquement les r√©sultats de votre agent. Vous pouvez configurer l'appel d'un autre LLM pour √©valuer l'exactitude, la toxicit√©, le style ou tout autre crit√®re qui vous int√©resse.\n",
    "\n",
    "**Fonctionnement** :\n",
    "1. Vous d√©finissez un **Mod√®le d'√©valuation**, par exemple, ¬´ V√©rifier si le texte est toxique ¬ª.\n",
    "2. Chaque fois que votre agent g√©n√®re un r√©sultat, vous transmettez ce r√©sultat √† votre LLM juge avec le gabarit.\n",
    "3. Le LLM juge r√©pond avec un score ou une √©tiquette que vous enregistrez dans votre outil d'observabilit√©.\n",
    "\n",
    "Exemple de Langfuse :\n",
    "\n",
    "![LLM-as-a-Judge Evaluation Template](https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/bonus-unit2/evaluator-template.png)\n",
    "![LLM-as-a-Judge Evaluator](https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/bonus-unit2/evaluator.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple : V√©rifier si la production de l'agent est toxique ou non\n",
    "from smolagents import (CodeAgent, DuckDuckGoSearchTool, InferenceClientModel)\n",
    "\n",
    "search_tool = DuckDuckGoSearchTool()\n",
    "agent = CodeAgent(tools=[search_tool], model=InferenceClientModel())\n",
    "\n",
    "agent.run(\"Can eating carrots improve your vision?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez voir que la r√©ponse de cet exemple est jug√©e ¬´ non toxique ¬ª.\n",
    "\n",
    "![LLM-as-a-Judge Evaluation Score](https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/bonus-unit2/llm-as-a-judge-score.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Aper√ßu des m√©triques d'observabilit√©\n",
    "\n",
    "Toutes ces m√©triques peuvent √™tre visualis√©es ensemble dans des tableaux de bord. Cela vous permet de voir rapidement les performances de votre agent sur plusieurs sessions et vous aide √† suivre les mesures de qualit√© au fil du temps.\n",
    "\n",
    "![Observability metrics overview](https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/bonus-unit2/langfuse-dashboard.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## √âvaluation hors ligne\n",
    "\n",
    "L'√©valuation en ligne est essentielle pour obtenir un retour d'information en temps r√©el, mais vous avez √©galement besoin d'une **√©valuation hors ligne**, c'est-√†-dire de v√©rifications syst√©matiques avant ou pendant le d√©veloppement. Cela permet de maintenir la qualit√© et la fiabilit√© avant de mettre les changements en production."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### √âvaluation d'un jeu de donn√©es\n",
    "\n",
    "Lors d'une √©valuation hors ligne, vous devez g√©n√©ralement\n",
    "1. Disposer d'un jeu de donn√©es de r√©f√©rence (avec des paires de *prompts* et de r√©sultats attendus)\n",
    "2. Ex√©cuter votre agent sur ce jeu de donn√©es\n",
    "3. Comparer les r√©sultats aux r√©sultats attendus ou utiliser un m√©canisme de notation suppl√©mentaire.\n",
    "\n",
    "Ci-dessous, nous d√©montrons cette approche avec le jeu de donn√©es [GSM8K](https://huggingface.co/datasets/gsm8k), qui contient des questions et des solutions math√©matiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "\n",
    "# R√©cup√©rer GSM8K sur Hugging Face\n",
    "dataset = load_dataset(\"openai/gsm8k\", 'main', split='train')\n",
    "df = pd.DataFrame(dataset)\n",
    "print(\"First few rows of GSM8K dataset:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuite, nous cr√©ons un jeu de donn√©es dans Langfuse pour suivre les ex√©cutions. Nous ajoutons ensuite chaque √©l√©ment du jeu de donn√©es au syst√®me.  \n",
    "(Si vous n'utilisez pas Langfuse, vous pouvez simplement les stocker dans votre propre base de donn√©es ou dans un fichier local √† des fins d'analyse)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse import get_client\n",
    "langfuse = get_client()\n",
    "\n",
    "langfuse_dataset_name = \"gsm8k_dataset_huggingface\"\n",
    "\n",
    "# Cr√©er un jeu de donn√©es dans Langfuse\n",
    "langfuse.create_dataset(\n",
    "    name=langfuse_dataset_name,\n",
    "    description=\"GSM8K benchmark dataset uploaded from Huggingface\",\n",
    "    metadata={\n",
    "        \"date\": \"2025-03-10\", \n",
    "        \"type\": \"benchmark\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in df.iterrows():\n",
    "    langfuse.create_dataset_item(\n",
    "        dataset_name=langfuse_dataset_name,\n",
    "        input={\"text\": row[\"question\"]},\n",
    "        expected_output={\"text\": row[\"answer\"]},\n",
    "        metadata={\"source_index\": idx}\n",
    "    )\n",
    "    if idx >= 9: # Ne t√©l√©charge que les 10 premiers √©l√©ments pour la d√©monstration\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Dataset items in Langfuse](https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/bonus-unit2/example-dataset.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ex√©cution de l'agent sur le jeu de donn√©es\n",
    "\n",
    "Nous d√©finissons une fonction d'aide `run_smolagent()` qui :\n",
    "1. D√©marre un span Langfuse\n",
    "2. Ex√©cute notre agent sur le *prompt*\n",
    "3. Enregistre l'ID de la trace dans Langfuse\n",
    "\n",
    "Ensuite, nous parcourons en boucle chaque √©l√©ment de l'ensemble de donn√©es, nous ex√©cutons l'agent et nous lions la trace √† l'√©l√©ment de l'ensemble de donn√©es. Nous pouvons √©galement joindre une note d'√©valuation rapide si vous le souhaitez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opentelemetry.trace import format_trace_id\n",
    "from smolagents import (CodeAgent, InferenceClientModel, LiteLLMModel)\n",
    "from langfuse import get_client\n",
    " \n",
    "langfuse = get_client()\n",
    "\n",
    "\n",
    "# Exemple : utilisation de InferenceClientModel ou LiteLLMModel pour acc√©der aux mod√®les openai, anthropic, gemini, etc. :\n",
    "model = InferenceClientModel()\n",
    "\n",
    "agent = CodeAgent(\n",
    "    tools=[],\n",
    "    model=model,\n",
    "    add_base_tools=True\n",
    ")\n",
    "\n",
    "dataset_name = \"gsm8k_dataset_huggingface\"\n",
    "current_run_name = \"smolagent-notebook-run-01\" # Identifie ce cycle d'√©valuation sp√©cifique\n",
    " \n",
    "# Supposons que ¬´ run_smolagent ¬ª soit la fonction de l'application instrument√©e\n",
    "def run_smolagent(question):\n",
    "    with langfuse.start_as_current_generation(name=\"qna-llm-call\") as generation:\n",
    "        # Simuler un appel LLM\n",
    "        result = agent.run(question)\n",
    " \n",
    "        # Mise √† jour de la trace avec l'entr√©e et la sortie\n",
    "        generation.update_trace(\n",
    "            input= question,\n",
    "            output=result,\n",
    "        )\n",
    " \n",
    "        return result\n",
    " \n",
    "dataset = langfuse.get_dataset(name=dataset_name) # R√©cup√©rez votre jeu de donn√©es pr√©-rempli\n",
    " \n",
    "for item in dataset.items:\n",
    " \n",
    "    # Utiliser le gestionnaire de contexte item.run()\n",
    "    with item.run(\n",
    "        run_name=current_run_name,\n",
    "        run_metadata={\"model_provider\": \"Hugging Face\", \"temperature_setting\": 0.7},\n",
    "        run_description=\"Evaluation run for GSM8K dataset\"\n",
    "    ) as root_span: # root_span est le span racine de la nouvelle trace pour cet √©l√©ment et l'ex√©cution.\n",
    "        # Toutes les op√©rations langfuse subs√©quentes √† l'int√©rieur de ce bloc font partie de cette trace.\n",
    " \n",
    "        # Appelez votre logique d'application\n",
    "        generated_answer = run_smolagent(question=item.input[\"text\"])\n",
    " \n",
    "        print(item.input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez r√©p√©ter ce processus avec diff√©rents :\n",
    "- Mod√®les (OpenAI GPT, LLM local, etc.)\n",
    "- Outils (recherche ou pas recherche)\n",
    "- Prompts (diff√©rents messages du syst√®me)\n",
    "\n",
    "Ensuite, comparez-les c√¥te √† c√¥te dans votre outil d'observabilit√© :\n",
    "\n",
    "![Dataset run overview](https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/bonus-unit2/dataset_runs.png)\n",
    "![Dataset run comparison](https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/bonus-unit2/dataset-run-comparison.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R√©flexions finales\n",
    "\n",
    "Dans ce *notebook*, nous avons vu comment :\n",
    "1. **Mettre en place l'observabilit√©** en utilisant les exportateurs smolagents + OpenTelemetry\n",
    "2. **V√©rifier l'instrumentation** en lan√ßant un agent simple\n",
    "3. **Capturez des m√©triques d√©taill√©es** (co√ªt, latence, etc.) √† l'aide d'outils d'observabilit√©\n",
    "4. **Recueillir les commentaires des utilisateurs** via une interface Gradio\n",
    "5. **Utiliser un LLM-as-a-Judge** pour √©valuer automatiquement les r√©sultats\n",
    "6. **Effectuer une √©valuation hors ligne** avec un jeu de donn√©es de r√©f√©rence\n",
    "\n",
    "ü§ó Bon codage !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
