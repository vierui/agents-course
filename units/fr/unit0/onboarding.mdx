# Embarquement : vos premiers pas â›µ

<img src="https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/unit0/time-to-onboard.jpg" alt="Il est temps de dÃ©marrer" width="100%"/>

Maintenant que vous avez tous les dÃ©tails, commenÃ§ons ! Nous allons rÃ©aliser quatre choses :

1. **CrÃ©er votre compte Hugging Face** si ce n'est pas dÃ©jÃ  fait  
2. **Vous inscrire Ã  Discord et vous prÃ©senter** (ne soyez pas timide ğŸ¤—)  
3. **Suivre le cours sur les agents** sur le ğŸ¤— Hub  
4. **Faire passer le mot** Ã  propos du cours

### Ã‰tape 1 : CrÃ©er votre compte Hugging Face

(Si ce n'est pas dÃ©jÃ  fait) crÃ©ez un compte Hugging Face <a href='https://huggingface.co/join' target='_blank'>ici</a>.

### Ã‰tape 2 : Rejoindre notre Discord

ğŸ‘‰ğŸ» Rejoignez notre serveur Discord <a href="https://discord.gg/UrrTSsSyjb" target="_blank">ici.</a>

Lorsque vous rejoignez, n'oubliez pas de vous prÃ©senter dans `#introduce-yourself`.

Nous disposons de plusieurs canaux liÃ©s aux agents :
- `agents-course-announcements` : pour les **derniÃ¨res informations portant sur le cours**.
- `ğŸ“-agents-course-general` : pour **les discussions gÃ©nÃ©rales et les bavardages**.
- `agents-course-questions` : pour **poser des questions et aider vos camarades**.
- `agents-course-showcase` : pour **prÃ©senter vos meilleurs agents**.

De plus, vous pouvez consulter :

- `smolagents` : pour **les discussions et l'assistance concernant la bibliothÃ¨que**.

Si c'est votre premiÃ¨re utilisation de Discord, nous avons rÃ©digÃ© un guide d'introduction pour vous donner les meilleures pratiques. Consultez [la section suivante](discord101).

### Ã‰tape 3 : Suivre l'organisation *Hugging Face Agent Course* sur le ğŸ¤— Hub

Restez Ã  jour avec les derniers matÃ©riels de cours, mises Ã  jour, et annonces **en suivant l'organisation du cours sur le Hub**.

ğŸ‘‰ Rendez-vous <a href="https://huggingface.co/agents-course" target="_blank">ici</a> et cliquez sur **suivre**.

<img src="https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/communication/hf_course_follow.gif" alt="Suivre" width="100%"/>

### Ã‰tape 4 : Faites passer le mot Ã  propos du cours

Aidez-nous Ã  rendre ce cours plus visible ! Il y a deux faÃ§ons de nous aider :

1. Montrez votre soutien en <a href="https://github.com/huggingface/agents-course" target="_blank">laissant une Ã©toile â­ sur le dÃ©pÃ´t du cours</a>.

<img src="https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/communication/please_star.gif" alt="Favoriser le dÃ©pÃ´t"/>

2. Partagez votre parcours d'apprentissage : faites savoir aux autres **que vous suivez ce cours** ! Nous avons prÃ©parÃ© une illustration que vous pouvez utiliser dans vos publications sur les rÃ©seaux sociaux.

<img src="https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/communication/share.png" alt="Partagez votre parcours d'apprentissage" width="100%"/>

Vous pouvez tÃ©lÃ©charger l'image en cliquant ğŸ‘‰ [ici](https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/communication/share.png?download=true)

### Ã‰tape 5 : ExÃ©cuter des modÃ¨les localement avec Ollama (En cas de limites de crÃ©dits)

1. **Installez Ollama**

    Suivez les instructions officielles <a href="https://ollama.com/download" target="_blank">ici.</a>

2. **TÃ©lÃ©chargez un modÃ¨le localement**
``` bash
    ollama pull qwen2:7b # Consultez le site web d'Ollama pour plus de modÃ¨les
```
3. **DÃ©marrez Ollama en arriÃ¨re-plan (dans un terminal)**
``` bash
    ollama serve
``` 
    Si vous rencontrez l'erreur "*listen tcp 127.0.0.1:11434: bind: address already in use*", vous pouvez utiliser la commande `sudo lsof -i :11434` pour identifier l'ID du processus (PID) qui utilise actuellement ce port. Si le processus est `ollama`, il est probable que le script d'installation ci-dessus ait dÃ©marrÃ© le service ollama, vous pouvez donc ignorer cette commande pour dÃ©marrer Ollama.

4. **Utilisez `LiteLLMModel` au lieu de `InferenceClientModel`**

   Pour utiliser le module `LiteLLMModel` dans `smolagents`, vous pouvez exÃ©cuter la commande `pip` pour installer le module.

``` bash
    pip install 'smolagents[litellm]'
```

``` python
    from smolagents import LiteLLMModel

    model = LiteLLMModel(
        model_id="ollama_chat/qwen2:7b",  # Ou essayez d'autres modÃ¨les supportÃ©s par Ollama
        api_base="http://127.0.0.1:11434",  # Serveur local Ollama par dÃ©faut
        num_ctx=8192,
    )
```

5. **Pourquoi cela fonctionne-t-il ?**
- Ollama sert des modÃ¨les localement en utilisant une API compatible avec OpenAI Ã  `http://localhost:11434`.
- `LiteLLMModel` est conÃ§u pour communiquer avec tout modÃ¨le qui supporte le format d'API OpenAI chat/completion.
- Cela signifie que vous pouvez simplement remplacer `InferenceClientModel` par `LiteLLMModel` sans autres changements de code nÃ©cessaires. C'est une solution transparente et prÃªte Ã  l'emploi.

FÃ©licitations ! ğŸ‰  
**Vous avez terminÃ© le processus d'embarquement** ! Vous Ãªtes maintenant prÃªt Ã  commencer Ã  en apprendre plus  sur les agents IA. Amusez-vous bien !

Continuez Ã  apprendre, restez formidable ğŸ¤—
