<CourseFloatingBanner 
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/#fileId=https://huggingface.co/agents-course/notebooks/blob/main/fr/unit2/smolagents/vision_agents.ipynb"},
]}
askForHelpUrl="http://hf.co/join/discord" />

# Agents visuel avec smolagents

> [!WARNING]
> Les exemples de cette section n√©cessitent l'acc√®s √† un mod√®le VLM puissant. Nous les avons test√©s en utilisant l'API GPT-4o.
> Cependant, <a href="./why_use_smolagents">Pourquoi utiliser smolagents</a> discute des solutions alternatives support√©es par smolagents et Hugging Face. Si vous souhaitez explorer d'autres options, assurez-vous de consulter cette section.

Doter les agents de capacit√©s visuelles est crucial pour r√©soudre des t√¢ches qui vont au-del√† du traitement de texte. De nombreux d√©fis du monde r√©el, comme la navigation web ou la compr√©hension de documents, n√©cessitent d'analyser un contenu visuel riche. Heureusement, `smolagents` fournit un support int√©gr√© pour les mod√®les de vision-langage (VLM), permettant aux agents de traiter et d'interpr√©ter efficacement les images.

Dans cet exemple, imaginez qu'Alfred soit charg√© de v√©rifier les identit√©s des invit√©s assistant √† la f√™te. Comme vous pouvez l'imaginer, Alfred pourrait ne pas √™tre familier avec tout le monde. Pour l'aider, nous pouvons utiliser un agent qui v√©rifie leur identit√© en recherchant des informations visuelles sur leur apparence en utilisant un VLM. Cela permettra √† Alfred de prendre des d√©cisions √©clair√©es sur qui peut entrer. Construisons cet exemple !

## Fournir des images au d√©but de l'ex√©cution de l'agent

> [!TIP]
> Vous pouvez suivre le code dans <a href="https://huggingface.co/agents-course/notebooks/blob/main/fr/unit2/smolagents/vision_agents.ipynb" target="_blank">ce <i>notebook</i></a> que vous pouvez ex√©cuter avec Google Colab.

Dans cette approche, les images sont transmises √† l'agent au d√©but et stock√©es comme `task_images` avec le *prompt* de t√¢che. L'agent traite ensuite ces images tout au long de son ex√©cution.

Consid√©rez le cas o√π Alfred veut v√©rifier les identit√©s des super-h√©ros assistant √† la f√™te. Il a d√©j√† un jeu de donn√©es d'images de f√™tes pr√©c√©dentes avec les noms des invit√©s. √âtant donn√© l'image d'un nouveau visiteur, l'agent peut la comparer avec le jeu de donn√©es existant et prendre une d√©cision sur leur entr√©e.

Dans ce cas, un invit√© essaie d'entrer, et Alfred soup√ßonne que ce visiteur pourrait √™tre le Joker se faisant passer pour Wonder Woman. Alfred doit v√©rifier les identit√©s pour emp√™cher quiconque d'ind√©sirable d'entrer.

Construisons l'exemple. D'abord, les images sont charg√©es. Dans ce cas, nous utilisons des images de Wikip√©dia pour garder l'exemple minimaliste, mais imaginez les cas d'usage possibles !

```python
from PIL import Image
import requests
from io import BytesIO

image_urls = [
    "https://upload.wikimedia.org/wikipedia/commons/e/e8/The_Joker_at_Wax_Museum_Plus.jpg", # Image du Joker
    "https://upload.wikimedia.org/wikipedia/en/9/98/Joker_%28DC_Comics_character%29.jpg" # Image du Joker
]

images = []
for url in image_urls:
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36" 
    }
    response = requests.get(url,headers=headers)
    image = Image.open(BytesIO(response.content)).convert("RGB")
    images.append(image)
```

Maintenant que nous avons les images, l'agent nous dira si un invit√© est vraiment un super-h√©ros (Wonder Woman) ou un m√©chant (le Joker).

```python
from smolagents import CodeAgent, OpenAIServerModel

model = OpenAIServerModel(model_id="gpt-4o")

# Instancier l'agent
agent = CodeAgent(
    tools=[],
    model=model,
    max_steps=20,
    verbosity_level=2
)

response = agent.run(
    """
    D√©crire le costume et le maquillage que porte le personnage de bande dessin√©e figurant sur ces photos et renvoyer la description.
    Indiquer si l'invit√© est le Joker ou Wonder Woman.
    """,
    images=images
)
```

Dans le cas de mon ex√©cution, la sortie est la suivante, bien qu'elle puisse varier dans votre cas, comme nous l'avons d√©j√† discut√© :

```python
    {
        'Costume et maquillage - Premi√®re image': (
            'Manteau violet et une cravate ou n≈ìud papillon de soie violette sur une chemise jaune moutarde.',
            'Peinture faciale blanche avec des traits exag√©r√©s, sourcils sombres, maquillage des yeux bleu, l√®vres rouges formant un large sourire.'
        ),
        'Costume et maquillage - Deuxi√®me image': (
            'Costume sombre avec une fleur sur le revers, tenant une carte √† jouer.',
            'Peau p√¢le, cheveux verts, l√®vres tr√®s rouges avec un sourire exag√©r√©.'
        ),
        'Identit√© du personnage': 'Ce personnage ressemble aux repr√©sentations connues du Joker des m√©dias de bande dessin√©e.'
    }
```

Dans ce cas, la sortie r√©v√®le que la personne se fait passer pour quelqu'un d'autre, donc nous pouvons emp√™cher le Joker d'entrer √† la f√™te !

## Fournir des images avec recherche dynamique

> [!TIP]
> Vous pouvez suivre le code dans <a href="https://huggingface.co/agents-course/notebooks/blob/main/unit2/smolagents/vision_web_browser.py" target="_blank">ce fichier Python</a>

L'approche pr√©c√©dente est pr√©cieuse et a de nombreux cas d'usage potentiels. Cependant, dans des situations o√π l'invit√© n'est pas dans la base de donn√©es, nous devons explorer d'autres fa√ßons de les identifier. Une solution possible est de r√©cup√©rer dynamiquement des images et des informations √† partir de sources externes, comme naviguer sur le web pour des d√©tails.

Dans cette approche, les images sont ajout√©es dynamiquement √† la m√©moire de l'agent pendant l'ex√©cution. Comme nous le savons, les agents dans `smolagents` sont bas√©s sur la classe `MultiStepAgent`, qui est une abstraction du *framework ReAct*. Cette classe op√®re dans un cycle structur√© o√π diverses variables et connaissances sont enregistr√©es √† diff√©rentes √©tapes :

1. **SystemPromptStep :** Stocke le *prompt* syst√®me.
2. **TaskStep :** Enregistre la requ√™te utilisateur et toute entr√©e fournie.
3. **ActionStep :** Capture les logs des actions de l'agent et les r√©sultats.

Cette approche structur√©e permet aux agents d'incorporer des informations visuelles dynamiquement et de r√©pondre de mani√®re adaptative aux t√¢ches √©volutives. Ci-dessous se trouve le diagramme que nous avons d√©j√† vu, illustrant le processus de flux de travail dynamique et comment diff√©rentes √©tapes s'int√®grent dans le cycle de vie de l'agent. Lors de la navigation, l'agent peut prendre des captures d'√©cran et les sauvegarder comme `observation_images` dans l'`ActionStep`.

![R√©cup√©ration d'images dynamique](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/smolagents-can-see/diagram_adding_vlms_smolagents.png)

Maintenant que nous comprenons le besoin, construisons notre exemple complet. Dans ce cas, Alfred veut un contr√¥le total sur le processus de v√©rification des invit√©s, donc naviguer pour des d√©tails devient une solution viable. Pour compl√©ter cet exemple, nous avons besoin d'un nouvel ensemble d'outils pour l'agent. De plus, nous utiliserons Selenium et Helium, qui sont des outils d'automatisation de navigateur. Cela nous permettra de construire un agent qui explore le web, recherchant des d√©tails sur un invit√© potentiel et r√©cup√©rant des informations de v√©rification. Installons les outils n√©cessaires :

```bash
pip install "smolagents[all]" helium selenium python-dotenv
```

Nous aurons besoin d'un ensemble d'outils d'agent sp√©cifiquement con√ßus pour la navigation, tels que `search_item_ctrl_f`, `go_back` et `close_popups`. Ces outils permettent √† l'agent d'agir comme une personne naviguant sur le web.

```python
@tool
def search_item_ctrl_f(text: str, nth_result: int = 1) -> str:
    """
    Recherche du texte sur la page actuelle via Ctrl + F et saute √† la ni√®me occurrence.
    Args:
        text: Le texte √† rechercher
        nth_result: Quelle occurrence aller (par d√©faut: 1)
    """
    elements = driver.find_elements(By.XPATH, f"//*[contains(text(), '{text}')]")
    if nth_result > len(elements):
        raise Exception(f"Correspondance n¬∞{nth_result} non trouv√©e (seulement {len(elements)} correspondances trouv√©es)")
    result = f"Trouv√© {len(elements)} correspondances pour '{text}'."
    elem = elements[nth_result - 1]
    driver.execute_script("arguments[0].scrollIntoView(true);", elem)
    result += f"Focalis√© sur l'√©l√©ment {nth_result} de {len(elements)}"
    return result


@tool
def go_back() -> None:
    """Retourne √† la page pr√©c√©dente."""
    driver.back()


@tool
def close_popups() -> str:
    """
    Ferme tout modal ou pop-up visible sur la page. Utilise ceci pour fermer les fen√™tres pop-up ! Cela ne fonctionne pas sur les banni√®res de consentement de cookies.
    """
    webdriver.ActionChains(driver).send_keys(Keys.ESCAPE).perform()
```

Nous avons √©galement besoin de fonctionnalit√©s pour sauvegarder des captures d'√©cran, car ce sera une partie essentielle de ce que notre agent *VLM* utilise pour accomplir la t√¢che. Cette fonctionnalit√© prend la capture d'√©cran et la sauvegarde dans `step_log.observations_images = [image.copy()]`, permettant √† l'agent de stocker et traiter les images dynamiquement pendant qu'il navigue.

```python
def save_screenshot(step_log: ActionStep, agent: CodeAgent) -> None:
    sleep(1.0)  # Laisser les animations JavaScript se produire avant de prendre la capture d'√©cran
    driver = helium.get_driver()
    current_step = step_log.step_number
    if driver is not None:
        for step_logs in agent.logs:  # Supprimer les captures d'√©cran pr√©c√©dentes des logs pour un traitement all√©g√©
            if isinstance(step_log, ActionStep) and step_log.step_number <= current_step - 2:
                step_logs.observations_images = None
        png_bytes = driver.get_screenshot_as_png()
        image = Image.open(BytesIO(png_bytes))
        print(f"Capture d'√©cran de navigateur captur√©e : {image.size} pixels")
        step_log.observations_images = [image.copy()]  # Cr√©er une copie pour s'assurer qu'elle persiste, important !

    # Mettre √† jour les observations avec l'URL actuelle
    url_info = f"URL actuelle : {driver.current_url}"
    step_log.observations = url_info if step_logs.observations is None else step_log.observations + "\n" + url_info
    return
```

Cette fonction est pass√©e √† l'agent comme `step_callback`, car elle est d√©clench√©e √† la fin de chaque √©tape pendant l'ex√©cution de l'agent. Cela permet √† l'agent de capturer et stocker dynamiquement des captures d'√©cran tout au long de son processus.

Maintenant, nous pouvons g√©n√©rer notre agent de vision pour naviguer sur le web, en lui fournissant les outils que nous avons cr√©√©s, avec le `DuckDuckGoSearchTool` pour explorer le web. Cet outil aidera l'agent √† r√©cup√©rer les informations n√©cessaires pour v√©rifier les identit√©s des invit√©s bas√©es sur des indices visuels.

```python
from smolagents import CodeAgent, OpenAIServerModel, DuckDuckGoSearchTool
model = OpenAIServerModel(model_id="gpt-4o")

agent = CodeAgent(
    tools=[DuckDuckGoSearchTool(), go_back, close_popups, search_item_ctrl_f],
    model=model,
    additional_authorized_imports=["helium"],
    step_callbacks=[save_screenshot],
    max_steps=20,
    verbosity_level=2,
)
```

Avec cela, Alfred est pr√™t √† v√©rifier les identit√©s des invit√©s et prendre des d√©cisions √©clair√©es sur s'il faut les laisser entrer ou non √† la f√™te :

```python
agent.run("""
Je suis Alfred, le majordome du manoir Wayne, charg√© de v√©rifier l'identit√© des invit√©s √† une f√™te. Une super-h√©ro√Øne se pr√©sente √† l'entr√©e en pr√©tendant √™tre Wonder Woman, mais je dois v√©rifier si elle est bien celle qu'elle pr√©tend √™tre.

Veuillez rechercher des images de Wonder Woman et g√©n√©rer une description visuelle d√©taill√©e √† partir de ces images. De plus, naviguez sur Wikip√©dia pour recueillir des d√©tails cl√©s sur son apparence. Gr√¢ce √† ces informations, je pourrai d√©terminer s'il convient de lui accorder l'acc√®s √† l'√©v√©nement.
""" + helium_instructions)
```

Vous pouvez voir que nous incluons `helium_instructions` dans le cadre de la t√¢che. Ce *prompt* sp√©cial vise √† contr√¥ler la navigation de l'agent, s'assurant qu'il suit les bonnes √©tapes lors de la navigation web.

Voyons comment cela fonctionne dans la vid√©o ci-dessous :

<iframe width="560" height="315" src="https://www.youtube.com/embed/rObJel7-OLc?si=TnNwQ8rqXqun_pqE" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

C'est la sortie finale :

```python
R√©ponse finale : Wonder Woman est typiquement repr√©sent√©e portant un bustier rouge et or, un short ou une jupe bleu avec des √©toiles blanches, un tiare dor√©, des bracelets argent√©s et un lasso de v√©rit√© dor√©. Elle est la Princesse Diana de Themyscira, connue sous le nom de Diana Prince dans le monde des hommes.
```

Avec tout cela, nous avons cr√©√© avec succ√®s notre v√©rificateur d'identit√© pour la f√™te ! Alfred a maintenant les outils n√©cessaires pour s'assurer que seuls les bons invit√©s franchissent la porte. Tout est pr√™t pour passer du bon temps au manoir Wayne !

## Lectures compl√©mentaires

- [Nous venons de donner la vue √† smolagents](https://huggingface.co/blog/smolagents-can-see) - Blog d√©crivant la fonctionnalit√© d'agent visuel.
- [Automatisation de navigateur web avec agents ü§ñüåê](https://huggingface.co/docs/smolagents/examples/web_browser) - Exemple pour la navigation web utilisant un agent visuel.
- [Exemple d'agent visuel pour navigateur web](https://github.com/huggingface/smolagents/blob/main/src/smolagents/vision_web_browser.py) - Exemple pour la navigation web utilisant un agent visuel.
